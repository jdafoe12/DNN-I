# DNN-I

#### About

This project was developed both for learning and teaching purposes. Most importantly, my aim was to build a **concrete** understanding, of how deep neural networks are trained and how inference works. To achieve this, I implemented everything from scratch, using no special libraries. This gave me much freedom in language choice. I chose Guile Scheme for a couple reasons:
- I thought it would be a good opportunity to be my first project written in Guile Scheme. I am (slowly) working my way through *Structure and Interpretation of Computer Programs (SICP)* and wanted to apply some of the learned principles.
- Given the history of lisp as a language for artificial intelligence applications, I thought it was a rather natural choice.

For my first DNN, I chose to work with the MNIST dataset, inspired largely by the [3Blue1Brown's neural network video series](https://www.3blue1brown.com/topics/neural-networks). My initial target was to achieve 97% or higher accuracy, and have achieved ---.

In designing this code, I focused on enabling rapid experimentation with different hyperparameters, so they could be tweaked for optimal performance.

---
#### Documentation

TODO Explain the various files, and implementation choices (defaults for training, for testings, and the activation functions used, loss function used.)


---

#### Setup and Usage

TODO You need to have Guile installed on your system and be able to run Guile code. Additionally, you need to have the MNIST dataset downloaded in the DNN-I directory. 